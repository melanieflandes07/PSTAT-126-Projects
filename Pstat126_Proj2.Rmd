---
title: "PSTAT 126 Project 2"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Problem 1

1. The R package \texttt{alr4} contains a dataset called \texttt{UN11} that includes the U.S national gross product per person (Predictor) and Fertility (Response). Answer for 1a.

```{r,fig.align='center'}
library(alr4)
```

## 1b) Ploting the data
```{r,fig.align='center'}
x=UN11$ppgdp
y=UN11$fertility
plot(x,y,xlab="ppgdp",ylab="Fertility")
## The trend is not linear
```

The trend in the plot appears to be not linear. 

## 1c) Replacing Variables 

```{r,fig.align='center'}
x1 = log(UN11$ppgdp)
y1 = log(UN11$fertility)
plot(x1,y1,xlab="Natural Log ppgdp",ylab="Natural Log Fertility")
```
The Simple Linear Regression Model is plausible for a summary of this graph.

## Problem 2

2. The R package \texttt{alr4} contains a dataset called \texttt{Heights} that includes the heights of families in England. The data set includes 1375 pairs of heights of mothers (mheight) and their daughters (dheights) in inches.

```{r,fig.align='center'}
library(alr4)
```

## 2a) Drawing the scatterplot 

```{r,fig.align='center'}
##Predictor = mheight response = dheight
x = Heights$mheight
y = Heights$dheight
plot(x,y,xlab="Heights of Mothers",ylab="Heights of Daughters")
```

## 2b) Computations
```{r,fig.align='center'}
##Computing x bar 
xbar = mean(x)
xbar

## Computing y bar
ybar = mean(y)
ybar

## Computing Sxx
Sxx = sum((x - xbar)^2)
Sxx

## Computing Syy
Syy = sum((y - ybar)^2)
Syy

## Computing Sxy
Sxy = sum((x - xbar)*(y - ybar))
Sxy

## Compute the Least Squares Estimate of Intercept
r = Sxy/(sqrt(Sxx*Syy))
r

## Compute the Slope for Simple Linear Regression Model 
b1 = r*(sqrt(Syy/Sxx))
b1
b0 = ybar - (b1*xbar)
b0

## Drawing the Fitted Line
plot(x,y,xlab="Heights of Mothers",ylab="Heights of Daughters")
abline(b0,b1)
```

## 2c) Computing Estimates and Standard Errors

```{r,fig.align='center'}
yhat = b0 + b1*x
e = y - yhat
n = length(x)
sigma2hat = (sum(e^2))/(n - 2)

## Estimated Standard Error
sigmahat = sqrt(sigma2hat)
sigmahat
```

## T testing 
```{r,fig.align='center'}
## Standard Error for b0
se_b0 = sigmahat*sqrt(1/n + mean(x)^2/Sxx)
se_b0

## Standard Error for b1
se_b1 = sigmahat/sqrt(Sxx)
se_b1

##T test for null Hypothesis where b0=0,Test Stat, P value
t_stat_b0 = b0/se_b0
t_stat_b0
p_val_b0 = pt(t_stat_b0,df = n - 2, lower.tail = FALSE)
p_val_b0

##T test for null hypothesis where b1=0, Test stat, P value
t_stat_b1 = b1/se_b1
t_stat_b1
p_val_b1 = pt(t_stat_b1, df = n - 2, lower.tail = FALSE)
p_val_b1
```

## 2d) 99% Confidence interval for $b1$
```{r,fig.align= 'center'}
t_pct = qt(p=.995, df = n - 2)
ci_b1_99 = b1 + c(-1,1) * se_b1 * qt(p=.995, df = (length(x)))
ci_b1_99 
```

## Problem 3

3. The R package \texttt{alr4} contains a dataset called \texttt{ftcollinstemp} that includes the temperatures of Fall and Winter. The dataset includes the temperatures in degree Farenheit of the temperatures of the years 1900 to 2010.

## 3a) Drawing the Regression line
```{r,fig.align='center'}
library(alr4)
attach(ftcollinstemp)
x = fall
y = winter
fit1 = lm(y ~ x)
plot(x,y,xlab= "Fall Temp", ylab = "Winter Temp")
abline(fit1$coef[1], fit1$coef[2])
```

## 3b) Testing the Null Hypothesis where the slope = 0
```{r, fig.align='center'}
## test H0: slope = 0 vs Ha: slope != 0
summary(fit1)
## Because the p value is less than your alpha = .05 
## this is significant evidence that the slope = 0. 
## therefore fall weather can predict winter weather, we accept the null hypothesis 
```

## 3c) Computing the 99% Confidence Interval
```{r, fig.align='center'}
## Compute the T percentile
t_pct = qt(p=.975, df = length(x) - 2)
sxx = sum((x-mean(x))^2)
fit1 = lm(y ~ x) 
yhat = fit1$coef[1] + fit1$coef[2] * x
e = y - yhat
sigma2hat = sum(e^2)/(length(x) - 2)
sigmahat = sqrt(sigma2hat)
se_b1 = sigmahat/sqrt(sxx)
## Confidence interval 99%
ci_b1_99 = fit1$coef[2] + c(-1,1) * t_pct * se_b1
ci_b1_99
```

## 3d) Conclusion
We are 99% confident that the true variation in winter is exmplained by the variation of fall lies within the interval (.2278,.3985).

## Problem 4

4. The R package \texttt{alr4} contains a dataset called \texttt{wblake} that includes the samples of small mouth bass collected in Minnesota. The data set includes the length and age of these bass. 

## 4a) Ploting the Regression Line
```{r, fig.align='center'}
library(alr4)
attach(wblake)
x = Age
y = Length
fit2 = lm(y ~ x)
plot(x,y,xlab="age",ylab="height")
abline(fit2$coef[1],fit2$coef[2])
```

## 4b) Testing the Null Hypothesis where slope = 0
```{r, fig.align='center'}
summary(fit2)

##Since the p value is less than our alpha value of .05, 
##we can reject our Null Hypothesis. 
##Therefore the slope does not equal to 0. 
```

## 4c) Finding the 95% Confidence Interval for mean length at age 4 years
```{r,fig.align='center'}
age = data.frame(x = 4)
predict(fit2, newdata = age, interval = "confidence", level = 0.95)
```

## 4d) Finding the 95% Confidence Interval for mean length at age 9 years
```{r,fig.align='center'}
age9 = data.frame(x = 9)
pre = predict(fit2, newdata = age9, interval = "confidence", level = 0.95)
pre
## This interval is not trustworthy because at the age of 9 years the 
## bass is not fully reached its full length. 
```


